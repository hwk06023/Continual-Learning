# Continual-Learning

![img](img/s1.png)

## Outline 

### What is Continual Learning


### Continual Learning's scenarios

### Regularization based

- Elastic Weight Consolidation (EWC)
- Memory Aware Synapses (MAS)
- Variational Continual Learning (VCL)
- Adaptive Group Sparsity based Continual Learning (AGS-CL)
- Less-Forgetting-Learning (LFL)
- Learning-Without-Forgetting (Lwf)
- Learning without Memorizing (LwM)

### Memory based

- Deep Generative Replay (DGR)
- Memory Replay GANs (MeRGAN)
- Dynamic Generative Memory (DGM)
- Gradient Episodic Memory (GEM) 
- Averaged GEM (A-GEM)- Experience replay (ER)

### Parameter isolation / Dynamic structure(architecture)

- Progressive Neural Network ( PNN ) 
- Dynamically Expandable Networks (DEN)
- Compacting, Picking and Growing (CPG) (+ PackNet, Piggyback, PAE )

- Conditional Channel Gated Networks  (CCGN)
- Dynamically Expandable Representation (DER)


## What is Continual Learning

![2](./img/s2.png)
![3](./img/s3.png)
![4](./img/s4.png)

## Continual Learning's scenarios

![5](./img/s5.png)

## Elastic Weight Consolidation (EWC)

[Ewc python code](./ewc.py)  <br/> <br/> <br/>




#### Reference 
https://arxiv.org/pdf/1612.00796.pdf <br/>
https://arxiv.org/pdf/1710.10628.pdf <br/>
https://arxiv.org/pdf/2003.13726.pdf <br/>
https://arxiv.org/pdf/1612.00796.pdf <br/>
https://arxiv.org/pdf/1706.08840.pdf <br/>
https://arxiv.org/pdf/1812.00420.pdf <br/>
https://arxiv.org/pdf/1511.05952.pdf <br/>
https://arxiv.org/pdf/2007.06700.pdf <br/>
https://arxiv.org/pdf/1606.04671.pdf <br/>
https://arxiv.org/pdf/1708.01547.pdf <br/>
https://arxiv.org/pdf/1910.06562.pdf <br/>
https://sjkim-icd.github.io